{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913ecffc-9c85-4735-abfe-6117fdbe0127",
   "metadata": {},
   "source": [
    "# Import modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fdd57d-4512-4f92-99e6-60d03bc6491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from owslib.wfs import WebFeatureService\n",
    "import shapely.wkt\n",
    "import geopandas as gpd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import urllib\n",
    "import urllib.request\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import fiona  # Importing fiona to handle geospatial data\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "import mapclassify\n",
    "import folium\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to install a package\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Ensure required packages are installed\n",
    "try:\n",
    "    import tqdm\n",
    "except ImportError as e:\n",
    "    package = str(e).split()[-1]\n",
    "    install(package)\n",
    "\n",
    "import warnings\n",
    "# Ignore FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Show all columns of datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acefbcbb-82cf-4781-82c4-fe63f22754d4",
   "metadata": {},
   "source": [
    "## File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db5053-3a8e-40b8-83b4-d7639d504de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define File Paths\n",
    "print(\"Step 2: Define File Paths\")\n",
    "municipality_workspace = r\"C:\\Users\\daphn\\Documents\\MADE_THESIS\\DATA\\RAW_DATA\\AMSTERDAM_MUNICIPALITY\\AmsterdamMunicipality.shp\"\n",
    "air_quality_folder = r\"C:\\Users\\daphn\\Documents\\MADE_THESIS\\DATA\\RAW_DATA\\DATA_AIR_QUALITY\\Clean_AMS_DataMixed_3Pollutants\"\n",
    "NO2_file = os.path.join(air_quality_folder, 'Clean_AMS_DataMixed_NO2_5Jul.shp')\n",
    "tree_canopy_path = r\"C:\\Users\\daphn\\Documents\\MADE_THESIS\\DATA\\CLEAN_DATA\\Clipped_Tree_Data.shp\"\n",
    "output_folder = r\"C:\\Users\\daphn\\Documents\\MADE_THESIS\\DATA\\CLEAN_DATA\\NO2_DISTRICT_TRAFFIC_ANALYSIS\"\n",
    "district_shp_folder = r\"C:\\Users\\daphn\\Documents\\MADE_THESIS\\DATA\\CLEAN_DATA\\DISTRICTS_SHAPES\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7178c68-8468-4b49-b501-948b295a5ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load Shapefiles\n",
    "print(\"Step 3: Load Shapefiles\")\n",
    "try:\n",
    "    municipality_boundary = gpd.read_file(municipality_workspace)\n",
    "    NO2_data = gpd.read_file(NO2_file)\n",
    "    tree_canopy_data = gpd.read_file(tree_canopy_path)\n",
    "    print(\"Shapefiles loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading shapefiles: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa62c36b-95f5-4fc9-bd41-f5b438b8f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Ensure Coordinate Systems Match\n",
    "print(\"Step 4: Ensure Coordinate Systems Match\")\n",
    "try:\n",
    "    municipality_crs = municipality_boundary.crs\n",
    "\n",
    "    if NO2_data.crs != municipality_crs:\n",
    "        NO2_data = NO2_data.to_crs(municipality_crs)\n",
    "        print(\"NO2 data reprojected to match municipality CRS\")\n",
    "\n",
    "    if tree_canopy_data.crs != municipality_crs:\n",
    "        tree_canopy_data = tree_canopy_data.to_crs(municipality_crs)\n",
    "        print(\"Tree canopy data reprojected to match municipality CRS\")\n",
    "\n",
    "    print(\"Coordinate systems verified and matched\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in checking/reprojecting CRS: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef18b74-ed70-4f6d-8125-220d2ebb3348",
   "metadata": {},
   "source": [
    "## Load study area and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5dc57-702f-4d76-a169-b444cac6b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Clip NO2 Data to the Municipality Boundary\n",
    "print(\"Step 5: Clip NO2 data to the municipality boundary\")\n",
    "try:\n",
    "    clipped_NO2_data = gpd.clip(NO2_data, municipality_boundary)\n",
    "    clipped_NO2_data.to_file(os.path.join(output_folder, \"clipped_NO2_data.shp\"))\n",
    "    print(\"NO2 data clipped successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in clipping NO2 data: {e}\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee2b1b8-79d2-4fba-bbed-aaf83f2cac02",
   "metadata": {},
   "source": [
    "## Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb6f02-9652-48a4-9ebe-2eff46a23878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Buffer the NO2 data\n",
    "print(\"Step 6: Buffer the NO2 data\")\n",
    "try:\n",
    "    buffer_distance = 15  # Buffer distance in meters\n",
    "    clipped_NO2_data['geometry'] = clipped_NO2_data.geometry.buffer(buffer_distance, cap_style='flat')\n",
    "    clipped_NO2_data['shp_area_bf'] = clipped_NO2_data.geometry.area\n",
    "    clipped_NO2_data.to_file(os.path.join(output_folder, \"buffered_NO2_data.shp\"))\n",
    "    print(\"Buffer creation completed\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in creating buffers: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9247f3-93a5-4019-98d1-10f91efe1af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Step 7: Process each buffer to identify trees within them and calculate the fraction of tree coverage\n",
    "print(\"Step 7: Identify trees within buffers and calculate sum of tree areas\")\n",
    "processed_buffers = []\n",
    "\n",
    "def process_buffer(buffer, tree_canopy, original_crs, visualize=False):\n",
    "    try:\n",
    "        # Use the original CRS from the GeoDataFrame to ensure the CRS matches\n",
    "        if tree_canopy.crs != original_crs:\n",
    "            tree_canopy = tree_canopy.to_crs(original_crs)\n",
    "            print(\"Reprojected tree canopy data to match buffer CRS\")\n",
    "\n",
    "        # Use a bounding box to filter trees and create a spatial index\n",
    "        buffer_bbox = buffer.geometry.bounds\n",
    "        filtered_trees = tree_canopy.cx[buffer_bbox[0]:buffer_bbox[2], buffer_bbox[1]:buffer_bbox[3]]\n",
    "        \n",
    "        # Build a spatial index for the filtered trees\n",
    "        sindex = filtered_trees.sindex\n",
    "        \n",
    "        # Filter further using spatial index and buffer intersection\n",
    "        possible_matches_index = list(sindex.intersection(buffer.geometry.bounds))\n",
    "        possible_matches = filtered_trees.iloc[possible_matches_index]\n",
    "        trees_within_buffer = possible_matches[possible_matches.intersects(buffer.geometry)]\n",
    "\n",
    "        # Perform a precise intersection to get only the intersecting parts\n",
    "        if not trees_within_buffer.empty:\n",
    "            # Clip the tree geometries to the buffer to get only the intersecting parts\n",
    "            trees_within_buffer['geometry'] = trees_within_buffer['geometry'].apply(lambda geom: geom.intersection(buffer.geometry))\n",
    "\n",
    "            # Calculate the area of the clipped geometries\n",
    "            intersection_area = trees_within_buffer.geometry.area.sum()\n",
    "\n",
    "            # Debugging: Print out the areas and geometry types to ensure correctness\n",
    "            print(f\"Buffer ID: {buffer.name}\")\n",
    "            print(f\"Buffer Area: {buffer['shp_area_bf']}\")\n",
    "            print(f\"Intersection Area (Tree Coverage): {intersection_area}\")\n",
    "            print(f\"Calculated Fraction: {intersection_area / buffer['shp_area_bf']}\")\n",
    "            print(f\"Tree Geometry Types after Intersection: {trees_within_buffer.geometry.type.unique()}\")\n",
    "        else:\n",
    "            intersection_area = 0\n",
    "\n",
    "        # Calculate the fraction of the buffer covered by tree canopy\n",
    "        buffer['sum_area_tb'] = intersection_area\n",
    "        buffer['frac_area_tb'] = intersection_area / buffer['shp_area_bf']\n",
    "\n",
    "        # If frac_area_tb is greater than 1, log a warning\n",
    "        if buffer['frac_area_tb'] > 1:\n",
    "            print(f\"Warning: frac_area_tb exceeded 1 for buffer at index {buffer.name}. Inspect the data.\")\n",
    "            return None\n",
    "\n",
    "        # Visualization: plot the buffer and intersecting trees\n",
    "        if visualize:\n",
    "            fig, ax = plt.subplots()\n",
    "            buffer_gdf = gpd.GeoDataFrame([buffer], crs=tree_canopy.crs)\n",
    "            buffer_gdf.plot(ax=ax, facecolor='none', edgecolor='blue', linewidth=2, label='Buffer')\n",
    "            trees_within_buffer.plot(ax=ax, color='green', alpha=0.5, label='Intersecting Trees')\n",
    "            plt.legend()\n",
    "            plt.title(f\"Buffer {buffer.name} and Intersecting Trees\")\n",
    "            plt.show()\n",
    "\n",
    "        return buffer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing buffer: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process all buffered NO2 data\n",
    "for idx, buffer in tqdm(clipped_NO2_data.iterrows(), total=clipped_NO2_data.shape[0]):\n",
    "    buffer_result = process_buffer(buffer, tree_canopy_data, clipped_NO2_data.crs, visualize=(idx == 0))  # Visualize the first buffer\n",
    "    if buffer_result is not None:\n",
    "        processed_buffers.append(buffer_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297f61f-f888-4089-9363-b599182768f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Combine processed buffers and save results\n",
    "if processed_buffers:\n",
    "    processed_buffers_gdf = gpd.GeoDataFrame(processed_buffers, crs=clipped_NO2_data.crs)\n",
    "    processed_buffers_gdf.to_file(os.path.join(output_folder, \"processed_buffers.shp\"))\n",
    "    print(\"Processed buffers successfully and saved\")\n",
    "else:\n",
    "    print(\"No buffers were processed successfully\")\n",
    "\n",
    "# Choose the index of the buffer you want to visualize (e.g., the second buffer)\n",
    "buffer_index = 35050\n",
    "\n",
    "# Index starts from 0, so 1 means the second buffer\n",
    "buffer_to_visualize = processed_buffers[buffer_index]\n",
    "\n",
    "# Proceed with the visualization\n",
    "buffer_geometry = buffer_to_visualize['geometry']\n",
    "intersecting_trees = tree_canopy_data[tree_canopy_data.intersects(buffer_geometry)]\n",
    "intersecting_trees['geometry'] = intersecting_trees['geometry'].apply(lambda geom: geom.intersection(buffer_geometry))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "gpd.GeoDataFrame([buffer_to_visualize], crs=tree_canopy_data.crs).plot(ax=ax, facecolor='none', edgecolor='blue', linewidth=2, label='Buffer')\n",
    "intersecting_trees.plot(ax=ax, color='green', alpha=0.5, label='Intersecting Trees')\n",
    "plt.legend()\n",
    "plt.title(f'Buffer {buffer_index + 1} and Intersecting Trees')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb851ec4-59a4-4743-afe0-ab405051c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c905ef-81d9-42da-bed7-800c083f65d2",
   "metadata": {},
   "source": [
    "## Visualization and Analysis (including scatter plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba4fec-d0ca-4105-80d1-6d43938ea092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Visualization and Analysis (including scatter plots)\n",
    "\n",
    "# Calculate and print the correlation\n",
    "correlation = processed_buffers_gdf['frac_area_tb'].corr(processed_buffers_gdf['NO2_Data'])\n",
    "print(f\"Correlation: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf40d5-4854-4c78-a0b1-6dcb41a9214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Analysis\n",
    "X = processed_buffers_gdf[['frac_area_tb']].values.reshape(-1, 1)\n",
    "y = processed_buffers_gdf['NO2_Data'].values\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "trend_line = model.predict(X)  # Generate the predicted values for the trend line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c7fcdc-c088-4d22-a3a0-68b6cff20028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Visualization and Analysis (including scatter plots)\n",
    "\n",
    "# Step 9: Visualization and Analysis (including scatter plots and histogram)\n",
    "\n",
    "# Calculate and print the correlation\n",
    "correlation = processed_buffers_gdf['frac_area_tb'].corr(processed_buffers_gdf['NO2_Data'])\n",
    "print(f\"Correlation: {correlation}\")\n",
    "\n",
    "# Linear Regression Analysis\n",
    "X = processed_buffers_gdf[['frac_area_tb']].values.reshape(-1, 1)\n",
    "y = processed_buffers_gdf['NO2_Data'].values\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "trend_line = model.predict(X)  # Generate the predicted values for the trend line\n",
    "\n",
    "# Scatter Plot with Trend Line\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(processed_buffers_gdf['frac_area_tb'], processed_buffers_gdf['NO2_Data'], alpha=0.5, label='Data Points')\n",
    "\n",
    "sorted_indices = np.argsort(processed_buffers_gdf['frac_area_tb'])\n",
    "sorted_frac_area_tb = processed_buffers_gdf['frac_area_tb'].values[sorted_indices]\n",
    "sorted_trend_line = trend_line[sorted_indices]\n",
    "\n",
    "# Plotting the trend line\n",
    "plt.plot(sorted_frac_area_tb, sorted_trend_line, color='red', label='Trend Line')\n",
    "\n",
    "plt.title('Scatter Plot of Tree Fraction vs. NO2 Data')\n",
    "plt.xlabel('Fraction of Trees')\n",
    "plt.ylabel('NO2 Data')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "# Save the scatter plot as PNG\n",
    "output_scatter_path = os.path.join(output_folder, \"scatter_plot_tree_vs_NO2.png\")\n",
    "plt.savefig(output_scatter_path)\n",
    "print(f\"Scatter Plot saved: {output_scatter_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Histogram of NO2 Data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(processed_buffers_gdf['NO2_Data'], bins=30, alpha=0.7, label='NO2 Data')\n",
    "plt.xlabel('NO2 Concentration')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of NO2 Data')\n",
    "\n",
    "# Save the histogram as PNG\n",
    "output_histogram_path = os.path.join(output_folder, \"histogram_NO2_data.png\")\n",
    "plt.savefig(output_histogram_path)\n",
    "print(f\"Histogram saved: {output_histogram_path}\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d1b29-0e52-47b1-855e-57aac3a3a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d805f813-0896-4dfe-a074-f9bcdf0b6321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Define file paths\n",
    "traffic_data_path = r\"C:\\Users\\daphn\\Documents\\MADE_THESIS\\DATA\\RAW_DATA\\DATA_TRAFFIC\\segment_noord-holland_p20008_mt2021_j2020_rpgw_s-compact (3)\\segment_noord-holland_p20008.shp\"\n",
    "processed_buffers_path = r\"C:\\Users\\daphn\\Documents\\MADE_THESIS\\DATA\\CLEAN_DATA\\NO2_DISTRICT_TRAFFIC_ANALYSIS\\processed_buffers.shp\"\n",
    "output_folder = r\"C:\\Users\\daphn\\Documents\\MADE_THESIS\\DATA\\CLEAN_DATA\\NO2_DISTRICT_TRAFFIC_ANALYSIS\"\n",
    "\n",
    "district_shp_folder = r\"C:\\Users\\daphn\\Documents\\MADE_THESIS\\DATA\\CLEAN_DATA\\DISTRICTS_SHAPES\"\n",
    "\n",
    "# Load traffic data\n",
    "traffic_data = gpd.read_file(traffic_data_path)\n",
    "print(f\"Traffic data loaded successfully. Columns: {traffic_data.columns}\")\n",
    "\n",
    "# Load processed buffers data\n",
    "processed_buffers_gdf = gpd.read_file(processed_buffers_path)\n",
    "print(f\"Processed buffers data loaded successfully. Columns: {processed_buffers_gdf.columns}\")\n",
    "\n",
    "# Check CRS for both datasets\n",
    "if traffic_data.crs != processed_buffers_gdf.crs:\n",
    "    traffic_data = traffic_data.to_crs(processed_buffers_gdf.crs)\n",
    "    print(\"Traffic data reprojected to match processed buffers CRS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f7866-7d75-46cb-9889-02229470bdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be760628-1833-4dc5-b082-63c46b823204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify traffic into quartiles\n",
    "def classify_into_quartiles(traffic_data, traffic_column='INT_LV'):\n",
    "    if traffic_column in traffic_data.columns:\n",
    "        traffic_data['Quartile'] = pd.qcut(traffic_data[traffic_column], 4, labels=['Bottom 25%', '25%-50%', '50%-75%', 'Top 25%'])\n",
    "        print(\"Traffic data classified into quartiles.\")\n",
    "    else:\n",
    "        print(f\"Traffic column '{traffic_column}' not found.\")\n",
    "    return traffic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31c834-4d37-46ba-95ad-2151b07478f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform spatial join between traffic and buffer data\n",
    "def perform_spatial_join(traffic_data, processed_buffers_gdf):\n",
    "    spatial_joined_gdf = gpd.sjoin(processed_buffers_gdf, traffic_data, how='inner', predicate='intersects')\n",
    "    print(\"Spatial join completed.\")\n",
    "    return spatial_joined_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd8dfce-5ae8-4a0c-9ed2-34c60267a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the traffic column to classify\n",
    "traffic_column = 'INT_LV'\n",
    "\n",
    "# Check if the traffic column exists\n",
    "if traffic_column in traffic_data.columns:\n",
    "    # Classify the traffic data into quartiles based on the traffic column\n",
    "    traffic_data['Quartile'] = pd.qcut(traffic_data[traffic_column], 4, labels=['Bottom 25%', '25%-50%', '50%-75%', 'Top 25%'])\n",
    "    print(\"Traffic data divided into quartiles. First few rows with Quartiles:\")\n",
    "    print(traffic_data[['SEGMENT_ID', traffic_column, 'Quartile']].head())\n",
    "else:\n",
    "    print(f\"Traffic column '{traffic_column}' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc47bbfc-2ad5-4d80-8042-c95953a00406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform spatial join between processed buffers and traffic data\n",
    "spatial_joined_gdf = gpd.sjoin(processed_buffers_gdf, traffic_data, how='inner', predicate='intersects')\n",
    "\n",
    "# Check the result of the spatial join\n",
    "print(\"Spatial join completed. First few rows of the joined dataset:\")\n",
    "print(spatial_joined_gdf.head())\n",
    "\n",
    "# List the columns in the joined GeoDataFrame to confirm\n",
    "print(\"Columns after spatial join:\", spatial_joined_gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8711978c-5fc5-409c-944e-948f87b72b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clip the data to the district boundary\n",
    "def clip_to_boundary(gdf, district_boundary):\n",
    "    clipped_gdf = gpd.clip(gdf, district_boundary)\n",
    "    return clipped_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87751c95-ab6a-4554-9521-9c2611a84951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and save maps for top 25% and bottom 25% traffic segments\n",
    "def create_traffic_map(district_name, district_boundary, top_25_gdf, bottom_25_gdf, output_folder):\n",
    "    # Create a plot for the district\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    # Plot the district boundary\n",
    "    district_boundary.plot(ax=ax, color='none', edgecolor='black', linewidth=2, label='District Boundary')\n",
    "\n",
    "    # Plot top 25% traffic data in red\n",
    "    if not top_25_gdf.empty:\n",
    "        top_25_gdf.plot(ax=ax, color='red', label='Top 25% Traffic', alpha=0.7)\n",
    "\n",
    "    # Plot bottom 25% traffic data in blue\n",
    "    if not bottom_25_gdf.empty:\n",
    "        bottom_25_gdf.plot(ax=ax, color='blue', label='Bottom 25% Traffic', alpha=0.7)\n",
    "\n",
    "    # Set axis limits to the district boundary\n",
    "    ax.set_xlim(district_boundary.total_bounds[0], district_boundary.total_bounds[2])\n",
    "    ax.set_ylim(district_boundary.total_bounds[1], district_boundary.total_bounds[3])\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.title(f\"Top and Bottom 25% Traffic in {district_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the plot\n",
    "    map_output_path = os.path.join(output_folder, f\"{district_name}_traffic_map.png\")\n",
    "    plt.savefig(map_output_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Map saved for {district_name} at {map_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09740730-046e-4802-aef7-faca8e718d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in processed_buffers_gdf:\", processed_buffers_gdf.columns)\n",
    "print(\"Columns in spatial_joined_gdf after join:\", spatial_joined_gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5450e60e-ba4e-4d30-b3bc-323ff207a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Function to create and save scatter plots for top and bottom 25% traffic segments\n",
    "def save_and_plot_top_bottom(gdf, data_column, title, output_folder):\n",
    "    # Filter for top 25% and bottom 25%\n",
    "    top_25_gdf = gdf[gdf['Quartile'] == 'Top 25%']\n",
    "    bottom_25_gdf = gdf[gdf['Quartile'] == 'Bottom 25%']\n",
    "    \n",
    "    def plot_data(filtered_gdf, subset_title):\n",
    "        if 'frac_area_' not in filtered_gdf.columns or data_column not in filtered_gdf.columns:\n",
    "            print(f\"Required columns 'frac_area_' or '{data_column}' are missing from the dataset.\")\n",
    "            return\n",
    "\n",
    "        # Scatter Plot with Trend Line\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(filtered_gdf['frac_area_'], filtered_gdf[data_column], alpha=0.5, label=f'{subset_title} Data Points')\n",
    "\n",
    "        # Linear regression\n",
    "        X = filtered_gdf[['frac_area_']].dropna()\n",
    "        y = filtered_gdf[data_column].dropna()\n",
    "        if not X.empty and not y.empty:\n",
    "            model = LinearRegression()\n",
    "            model.fit(X, y)\n",
    "            trend_line = model.predict(X)\n",
    "            plt.plot(X, trend_line, 'r--', label='Trend Line')\n",
    "            correlation = X['frac_area_'].corr(y)\n",
    "            coef = model.coef_[0]\n",
    "            intercept = model.intercept_\n",
    "            print(f\"Correlation: {correlation}, Coefficient: {coef}, Intercept: {intercept}\")\n",
    "        else:\n",
    "            print(f\"No valid data for regression in {subset_title}\")\n",
    "\n",
    "        plt.xlabel('Fraction of Trees')\n",
    "        plt.ylabel('NO2 Data µg/m3')\n",
    "        plt.title(f'Scatter Plot of {data_column} ({subset_title})')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "\n",
    "        # Save scatter plot\n",
    "        scatter_png_path = os.path.join(output_folder, f\"{subset_title.replace(' ', '_')}_scatter.png\")\n",
    "        plt.savefig(scatter_png_path, dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "    # Plot for Top 25%\n",
    "    plot_data(top_25_gdf, f\"{title} - Top 25% Traffic\")\n",
    "\n",
    "    # Plot for Bottom 25%\n",
    "    plot_data(bottom_25_gdf, f\"{title} - Bottom 25% Traffic\")\n",
    "\n",
    "# Function to process each district and generate maps and scatter plots\n",
    "def process_district_for_maps_and_plots(district_name, traffic_data, processed_buffers_gdf, output_folder):\n",
    "    print(f\"\\nProcessing district: {district_name}\")\n",
    "    \n",
    "    # Load district boundary shapefile\n",
    "    district_shapefile = os.path.join(district_shp_folder, f\"{district_name}.shp\")\n",
    "    district_boundary = gpd.read_file(district_shapefile)\n",
    "    \n",
    "    # Ensure CRS consistency (reproject if necessary)\n",
    "    if traffic_data.crs != 'EPSG:28992':\n",
    "        traffic_data = traffic_data.to_crs(epsg=28992)\n",
    "    if processed_buffers_gdf.crs != 'EPSG:28992':\n",
    "        processed_buffers_gdf = processed_buffers_gdf.to_crs(epsg=28992)\n",
    "    if district_boundary.crs != 'EPSG:28992':\n",
    "        district_boundary = district_boundary.to_crs(epsg=28992)\n",
    "\n",
    "    # Clip traffic data and processed buffers to the district boundary\n",
    "    traffic_data_clipped = gpd.clip(traffic_data, district_boundary)\n",
    "    processed_buffers_clipped = gpd.clip(processed_buffers_gdf, district_boundary)\n",
    "    \n",
    "    # Classify traffic data into quartiles\n",
    "    traffic_data_clipped = classify_into_quartiles(traffic_data_clipped, 'INT_LV')\n",
    "\n",
    "    # Perform spatial join for the traffic and processed buffers\n",
    "    spatial_joined_gdf = gpd.sjoin(traffic_data_clipped, processed_buffers_clipped, how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "    # Filter for top 25% and bottom 25% traffic\n",
    "    top_25_gdf = spatial_joined_gdf[spatial_joined_gdf['Quartile'] == 'Top 25%']\n",
    "    bottom_25_gdf = spatial_joined_gdf[spatial_joined_gdf['Quartile'] == 'Bottom 25%']\n",
    "\n",
    "    # Check if the data exists for both top and bottom 25%\n",
    "    if top_25_gdf.empty:\n",
    "        print(f\"No top 25% traffic data available for {district_name}\")\n",
    "    if bottom_25_gdf.empty:\n",
    "        print(f\"No bottom 25% traffic data available for {district_name}\")\n",
    "\n",
    "    # Create and save the scatter plots for top and bottom 25%\n",
    "    save_and_plot_top_bottom(spatial_joined_gdf, 'NO2_Data', district_name, output_folder)\n",
    "\n",
    "# Define districts (update this with actual district names)\n",
    "districts = [\"Centrum\", \"Nieuw-West\", \"West\", \"Zuid\", \"Noord\", \"Oost\", \"Zuidoost\"]\n",
    "\n",
    "# Run for all districts\n",
    "for district_name in districts:\n",
    "    process_district_for_maps_and_plots(district_name, traffic_data, processed_buffers_gdf, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a6796c-32cc-42eb-b18b-751ed8cda6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5382fee9-b6fa-4b61-a9ee-25f0c46c5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and save maps showing top 25% and bottom 25% traffic data with color differentiation\n",
    "def create_clipping_map_with_quartiles(district_name, district_boundary, spatial_joined_gdf, output_folder):\n",
    "    # Create a plot for the district\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    # Plot the district boundary\n",
    "    district_boundary.plot(ax=ax, color='none', edgecolor='black', linewidth=2, label='District Boundary')\n",
    "\n",
    "    # Filter for top 25% and bottom 25% traffic\n",
    "    top_25_gdf = spatial_joined_gdf[spatial_joined_gdf['Quartile'] == 'Top 25%']\n",
    "    bottom_25_gdf = spatial_joined_gdf[spatial_joined_gdf['Quartile'] == 'Bottom 25%']\n",
    "\n",
    "    # Plot top 25% traffic data in red\n",
    "    if not top_25_gdf.empty:\n",
    "        top_25_gdf.plot(ax=ax, color='red', label='Top 25% Traffic', alpha=0.7)\n",
    "\n",
    "    # Plot bottom 25% traffic data in blue\n",
    "    if not bottom_25_gdf.empty:\n",
    "        bottom_25_gdf.plot(ax=ax, color='blue', label='Bottom 25% Traffic', alpha=0.7)\n",
    "\n",
    "    # Set axis limits to the district boundary\n",
    "    ax.set_xlim(district_boundary.total_bounds[0], district_boundary.total_bounds[2])\n",
    "    ax.set_ylim(district_boundary.total_bounds[1], district_boundary.total_bounds[3])\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.title(f\"Top and Bottom 25% Traffic in {district_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the plot\n",
    "    map_output_path = os.path.join(output_folder, f\"{district_name}_traffic_map_with_quartiles.png\")\n",
    "    plt.savefig(map_output_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Map with quartiles saved for {district_name} at {map_output_path}\")\n",
    "\n",
    "# Function to create and save combined violin and box plot, as well as a histogram for all traffic quartiles\n",
    "def save_and_plot_statistical_analysis(gdf, data_column, title, output_folder):\n",
    "    # Ensure the necessary columns exist\n",
    "    if 'Quartile' not in gdf.columns or data_column not in gdf.columns:\n",
    "        print(f\"Error: Required columns 'Quartile' or '{data_column}' are missing from the dataset.\")\n",
    "        print(f\"Columns available in the data: {gdf.columns}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Generating plots for {title} using {data_column}...\")\n",
    "\n",
    "    # Combined Violin and Box Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.violinplot(x='Quartile', y=data_column, data=gdf, inner=None, color='lightgray', alpha=0.6)\n",
    "    sns.boxplot(x='Quartile', y=data_column, data=gdf, width=0.2, boxprops=dict(alpha=0.6))\n",
    "\n",
    "    plt.title(f'Combined Violin and Box Plot of {data_column} ({title})')\n",
    "    plt.xlabel('Traffic Quartile')\n",
    "    plt.ylabel('NO2 Data µg/m3')\n",
    "    plt.grid(True)\n",
    "\n",
    "    combined_violin_boxplot_path = os.path.join(output_folder, f\"{title.replace(' ', '_')}_combined_violin_boxplot.png\")\n",
    "    plt.savefig(combined_violin_boxplot_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"Combined violin and box plot saved at: {combined_violin_boxplot_path}\")\n",
    "\n",
    "    # Histogram for each quartile\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(gdf, x=data_column, hue='Quartile', multiple='stack', bins=30)\n",
    "    plt.title(f'Histogram of {data_column} by Quartile ({title})')\n",
    "    plt.xlabel('NO2 Data µg/m3')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "\n",
    "    hist_png_path = os.path.join(output_folder, f\"{title.replace(' ', '_')}_histogram.png\")\n",
    "    plt.savefig(hist_png_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"Histogram saved at: {hist_png_path}\")\n",
    "\n",
    "    print(f\"Statistical analysis saved for {title}\")\n",
    "\n",
    "# Function to process each district, generate maps, and save statistical plots\n",
    "def process_district_for_analysis(district_name, traffic_data, processed_buffers_gdf, output_folder, data_column):\n",
    "    print(f\"\\nProcessing district: {district_name}\")\n",
    "    \n",
    "    # Load district boundary shapefile\n",
    "    district_shapefile = os.path.join(district_shp_folder, f\"{district_name}.shp\")\n",
    "    district_boundary = gpd.read_file(district_shapefile)\n",
    "    \n",
    "    # Ensure CRS consistency (reproject if necessary)\n",
    "    if traffic_data.crs != 'EPSG:28992':\n",
    "        traffic_data = traffic_data.to_crs(epsg=28992)\n",
    "    if processed_buffers_gdf.crs != 'EPSG:28992':\n",
    "        processed_buffers_gdf = processed_buffers_gdf.to_crs(epsg=28992)\n",
    "    if district_boundary.crs != 'EPSG:28992':\n",
    "        district_boundary = district_boundary.to_crs(epsg=28992)\n",
    "\n",
    "    # Clip traffic data and processed buffers to the district boundary\n",
    "    traffic_data_clipped = gpd.clip(traffic_data, district_boundary)\n",
    "    processed_buffers_clipped = gpd.clip(processed_buffers_gdf, district_boundary)\n",
    "    \n",
    "    # Perform spatial join for the traffic and processed buffers\n",
    "    spatial_joined_gdf = gpd.sjoin(traffic_data_clipped, processed_buffers_clipped, how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "    # Generate the clipping map with quartiles\n",
    "    create_clipping_map_with_quartiles(district_name, district_boundary, spatial_joined_gdf, output_folder)\n",
    "    \n",
    "    # Perform and save the statistical analysis\n",
    "    save_and_plot_statistical_analysis(spatial_joined_gdf, data_column, district_name, output_folder)\n",
    "\n",
    "# Define districts (update this with actual district names)\n",
    "districts = [\"Centrum\", \"Nieuw-West\", \"West\", \"Zuid\", \"Noord\", \"Oost\", \"Zuidoost\"]\n",
    "\n",
    "# Define data column for analysis (update this with the correct column name, e.g., 'NO2_Data')\n",
    "data_column = 'NO2_Data'\n",
    "\n",
    "# Run for all districts\n",
    "for district_name in districts:\n",
    "    process_district_for_analysis(district_name, traffic_data, processed_buffers_gdf, output_folder, data_column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe00bf-33cb-4746-8c6b-6a5ba1a9290e",
   "metadata": {},
   "source": [
    "## Calculate # of streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf80ad1-2ae6-4a15-94e6-5ecdbba350cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the percentage of streets in the top 25% and bottom 25% per district\n",
    "def calculate_street_percentages(spatial_joined_gdf, district_name):\n",
    "    total_streets = len(spatial_joined_gdf)\n",
    "    top_25_streets = len(spatial_joined_gdf[spatial_joined_gdf['Quartile'] == 'Top 25%'])\n",
    "    bottom_25_streets = len(spatial_joined_gdf[spatial_joined_gdf['Quartile'] == 'Bottom 25%'])\n",
    "\n",
    "    # Calculate percentages\n",
    "    top_25_percentage = (top_25_streets / total_streets) * 100 if total_streets > 0 else 0\n",
    "    bottom_25_percentage = (bottom_25_streets / total_streets) * 100 if total_streets > 0 else 0\n",
    "\n",
    "    print(f\"{district_name} - Top 25% Streets: {top_25_percentage:.2f}% ({top_25_streets}/{total_streets})\")\n",
    "    print(f\"{district_name} - Bottom 25% Streets: {bottom_25_percentage:.2f}% ({bottom_25_streets}/{total_streets})\")\n",
    "    return top_25_percentage, bottom_25_percentage\n",
    "\n",
    "# Function to process each district and calculate street percentages\n",
    "def process_district_for_street_analysis(district_name, traffic_data, processed_buffers_gdf, output_folder):\n",
    "    print(f\"\\nProcessing district: {district_name}\")\n",
    "    \n",
    "    # Load district boundary shapefile\n",
    "    district_shapefile = os.path.join(district_shp_folder, f\"{district_name}.shp\")\n",
    "    district_boundary = gpd.read_file(district_shapefile)\n",
    "    \n",
    "    # Ensure CRS consistency (reproject if necessary)\n",
    "    if traffic_data.crs != 'EPSG:28992':\n",
    "        traffic_data = traffic_data.to_crs(epsg=28992)\n",
    "    if processed_buffers_gdf.crs != 'EPSG:28992':\n",
    "        processed_buffers_gdf = processed_buffers_gdf.to_crs(epsg=28992)\n",
    "    if district_boundary.crs != 'EPSG:28992':\n",
    "        district_boundary = district_boundary.to_crs(epsg=28992)\n",
    "\n",
    "    # Clip traffic data and processed buffers to the district boundary\n",
    "    traffic_data_clipped = gpd.clip(traffic_data, district_boundary)\n",
    "    processed_buffers_clipped = gpd.clip(processed_buffers_gdf, district_boundary)\n",
    "    \n",
    "    # Classify traffic data into quartiles\n",
    "    traffic_data_clipped = classify_into_quartiles(traffic_data_clipped, 'INT_LV')\n",
    "\n",
    "    # Perform spatial join for the traffic and processed buffers\n",
    "    spatial_joined_gdf = gpd.sjoin(traffic_data_clipped, processed_buffers_clipped, how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "    # Calculate street percentages for top and bottom 25%\n",
    "    top_25_percentage, bottom_25_percentage = calculate_street_percentages(spatial_joined_gdf, district_name)\n",
    "\n",
    "# Define districts (update this with actual district names)\n",
    "districts = [\"Centrum\", \"Nieuw-West\", \"West\", \"Zuid\", \"Noord\", \"Oost\", \"Zuidoost\"]\n",
    "\n",
    "# Run for all districts\n",
    "for district_name in districts:\n",
    "    process_district_for_street_analysis(district_name, traffic_data, processed_buffers_gdf, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d5d814-7f04-436c-b278-57fcf81f6e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b35cb6-20c5-4385-b383-217e46e4d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "# Function to create and save maps showing top 25% and bottom 25% traffic data with color differentiation\n",
    "def create_clipping_map_with_quartiles(district_name, district_boundary, spatial_joined_gdf, output_folder):\n",
    "    # Create a plot for the district\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    # Plot the district boundary\n",
    "    district_boundary.plot(ax=ax, color='none', edgecolor='black', linewidth=2, label='District Boundary')\n",
    "\n",
    "    # Filter for top 25% and bottom 25% traffic\n",
    "    top_25_gdf = spatial_joined_gdf[spatial_joined_gdf['Quartile'] == 'Top 25%']\n",
    "    bottom_25_gdf = spatial_joined_gdf[spatial_joined_gdf['Quartile'] == 'Bottom 25%']\n",
    "\n",
    "    # Plot top 25% traffic data in red\n",
    "    if not top_25_gdf.empty:\n",
    "        top_25_gdf.plot(ax=ax, color='red', label='Top 25% Traffic', alpha=0.7)\n",
    "\n",
    "    # Plot bottom 25% traffic data in blue\n",
    "    if not bottom_25_gdf.empty:\n",
    "        bottom_25_gdf.plot(ax=ax, color='blue', label='Bottom 25% Traffic', alpha=0.7)\n",
    "\n",
    "    # Set axis limits to the district boundary\n",
    "    ax.set_xlim(district_boundary.total_bounds[0], district_boundary.total_bounds[2])\n",
    "    ax.set_ylim(district_boundary.total_bounds[1], district_boundary.total_bounds[3])\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.title(f\"Top and Bottom 25% Traffic in {district_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the plot\n",
    "    map_output_path = os.path.join(output_folder, f\"{district_name}_traffic_map_with_quartiles.png\")\n",
    "    plt.savefig(map_output_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Map with quartiles saved for {district_name} at {map_output_path}\")\n",
    "\n",
    "# Function to create and save box plot, violin plot, and histogram for all traffic quartiles\n",
    "def save_and_plot_statistical_analysis(gdf, data_column, title, output_folder):\n",
    "    # Ensure the necessary columns exist\n",
    "    if 'Quartile' not in gdf.columns or data_column not in gdf.columns:\n",
    "        print(f\"Error: Required columns 'Quartile' or '{data_column}' are missing from the dataset.\")\n",
    "        print(f\"Columns available in the data: {gdf.columns}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Generating plots for {title} using {data_column}...\")\n",
    "\n",
    "    # Box Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='Quartile', y=data_column, data=gdf)\n",
    "    plt.title(f'Box Plot of {data_column} ({title})')\n",
    "    plt.xlabel('Traffic Quartile')\n",
    "    plt.ylabel(data_column)\n",
    "    plt.grid(True)\n",
    "\n",
    "    box_png_path = os.path.join(output_folder, f\"{title.replace(' ', '_')}_box.png\")\n",
    "    plt.savefig(box_png_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"Box plot saved at: {box_png_path}\")\n",
    "\n",
    "    # Violin Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.violinplot(x='Quartile', y=data_column, data=gdf)\n",
    "    plt.title(f'Violin Plot of {data_column} ({title})')\n",
    "    plt.xlabel('Traffic Quartile')\n",
    "    plt.ylabel(data_column)\n",
    "    plt.grid(True)\n",
    "\n",
    "    violin_png_path = os.path.join(output_folder, f\"{title.replace(' ', '_')}_violin.png\")\n",
    "    plt.savefig(violin_png_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"Violin plot saved at: {violin_png_path}\")\n",
    "\n",
    "    # Histogram for each quartile\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(gdf, x=data_column, hue='Quartile', multiple='stack', bins=30)\n",
    "    plt.title(f'Histogram of {data_column} by Quartile ({title})')\n",
    "    plt.xlabel(data_column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "\n",
    "    hist_png_path = os.path.join(output_folder, f\"{title.replace(' ', '_')}_histogram.png\")\n",
    "    plt.savefig(hist_png_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"Histogram saved at: {hist_png_path}\")\n",
    "\n",
    "    print(f\"Statistical analysis saved for {title}\")\n",
    "\n",
    "# Function to process each district, generate maps, and save statistical plots\n",
    "def process_district_for_analysis(district_name, traffic_data, processed_buffers_gdf, output_folder, data_column):\n",
    "    print(f\"\\nProcessing district: {district_name}\")\n",
    "    \n",
    "    # Load district boundary shapefile\n",
    "    district_shapefile = os.path.join(district_shp_folder, f\"{district_name}.shp\")\n",
    "    district_boundary = gpd.read_file(district_shapefile)\n",
    "    \n",
    "    # Ensure CRS consistency (reproject if necessary)\n",
    "    if traffic_data.crs != 'EPSG:28992':\n",
    "        traffic_data = traffic_data.to_crs(epsg=28992)\n",
    "    if processed_buffers_gdf.crs != 'EPSG:28992':\n",
    "        processed_buffers_gdf = processed_buffers_gdf.to_crs(epsg=28992)\n",
    "    if district_boundary.crs != 'EPSG:28992':\n",
    "        district_boundary = district_boundary.to_crs(epsg=28992)\n",
    "\n",
    "    # Clip traffic data and processed buffers to the district boundary\n",
    "    traffic_data_clipped = gpd.clip(traffic_data, district_boundary)\n",
    "    processed_buffers_clipped = gpd.clip(processed_buffers_gdf, district_boundary)\n",
    "    \n",
    "    # Perform spatial join for the traffic and processed buffers\n",
    "    spatial_joined_gdf = gpd.sjoin(traffic_data_clipped, processed_buffers_clipped, how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "    # Generate the clipping map with quartiles\n",
    "    create_clipping_map_with_quartiles(district_name, district_boundary, spatial_joined_gdf, output_folder)\n",
    "    \n",
    "    # Perform and save the statistical analysis\n",
    "    save_and_plot_statistical_analysis(spatial_joined_gdf, data_column, district_name, output_folder)\n",
    "\n",
    "# Define districts (update this with actual district names)\n",
    "districts = [\"Centrum\", \"Nieuw-West\", \"West\", \"Zuid\", \"Noord\", \"Oost\", \"Zuidoost\"]\n",
    "\n",
    "# Define data column for analysis (update this with the correct column name, e.g., 'NO2_Data')\n",
    "data_column = 'NO2_Data'\n",
    "\n",
    "# Run for all districts\n",
    "for district_name in districts:\n",
    "    process_district_for_analysis(district_name, traffic_data, processed_buffers_gdf, output_folder, data_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d939885-72fb-46d1-a62d-f54a07faa22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1dc7a2-3350-4d2b-ba08-e14b2914a21f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e62618-04b3-48e4-ad97-e1238011094b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ea5bbb-bbf6-4d08-bcf4-ebce00e615f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d379212-e876-4468-bae2-8423e1db9bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a0ff5d-af69-4e23-9dae-ba9d224ad901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dfae3a-18a2-4a3d-9846-48492d0ddf58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de358a-d27d-4b2a-94f2-052c6ad96425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3207310-3137-42e5-88b2-9d7557a8cb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a206765-336f-4fe9-84de-5f2206dd5179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a20cd9-efb3-410d-887c-690f27e8d046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82919394-0217-42ab-b6cf-0221a272bb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cee73a-2725-4769-b80a-b33720b9c513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8269f9f9-c76a-4858-bc94-8cc66d3b8996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604177ea-87eb-48d1-94e4-a1666d90bead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Visualization and Analysis (including scatter plots)\n",
    "\n",
    "# Step 9: Visualization and Analysis (including scatter plots and histogram)\n",
    "\n",
    "# Calculate and print the correlation\n",
    "correlation = processed_buffers_gdf['frac_area_tb'].corr(processed_buffers_gdf['NO2_Mixed'])\n",
    "print(f\"Correlation: {correlation}\")\n",
    "\n",
    "# Linear Regression Analysis\n",
    "X = processed_buffers_gdf[['frac_area_tb']].values.reshape(-1, 1)\n",
    "y = processed_buffers_gdf['NO2_Mixed'].values\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "trend_line = model.predict(X)  # Generate the predicted values for the trend line\n",
    "\n",
    "# Scatter Plot with Trend Line\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(processed_buffers_gdf['frac_area_tb'], processed_buffers_gdf['NO2_Mixed'], alpha=0.5, label='Data Points')\n",
    "\n",
    "sorted_indices = np.argsort(processed_buffers_gdf['frac_area_tb'])\n",
    "sorted_frac_area_tb = processed_buffers_gdf['frac_area_tb'].values[sorted_indices]\n",
    "sorted_trend_line = trend_line[sorted_indices]\n",
    "\n",
    "# Plotting the trend line\n",
    "plt.plot(sorted_frac_area_tb, sorted_trend_line, color='red', label='Trend Line')\n",
    "\n",
    "plt.title('Scatter Plot of Tree Fraction vs. NO2 Mixed')\n",
    "plt.xlabel('Fraction of Trees')\n",
    "plt.ylabel('NO2 Mixed')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "# Save the scatter plot as PNG\n",
    "output_scatter_path = os.path.join(output_folder, \"scatter_plot_tree_vs_NO2_mixed.png\")\n",
    "plt.savefig(output_scatter_path)\n",
    "print(f\"Scatter Plot saved: {output_scatter_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Histogram of NO2 Data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(processed_buffers_gdf['NO2_Mixed'], bins=30, alpha=0.7, label='NO2 Data Mixed')\n",
    "plt.xlabel('NO2 Concentration')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of NO2 Data Mixed')\n",
    "\n",
    "# Save the histogram as PNG\n",
    "output_histogram_path = os.path.join(output_folder, \"histogram_NO2_data_mixed.png\")\n",
    "plt.savefig(output_histogram_path)\n",
    "print(f\"Histogram saved: {output_histogram_path}\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437703a1-e4d5-4f86-b3dd-f04127cf053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 9: Generate Histograms for the Whole City and Each District\")\n",
    "\n",
    "# Histogram for the whole city\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(processed_buffers_gdf['frac_area_tb'], bins=30, alpha=0.7, label='Tree Fraction (City)')\n",
    "plt.xlabel('Fraction of Tree Canopy Coverage')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Tree Canopy Coverage Fraction - Whole City')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a6a52e-fc5e-4cc8-ab92-9ba2fb399b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat Maps\n",
    "def plot_heat_map(gdf, column, title, cmap='YlOrRd'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    gdf.plot(column=column, ax=ax, legend=True, cmap=cmap)\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_heat_map(processed_buffers_gdf, 'NO2_Data', 'NO2 Concentration Heat Map')\n",
    "plot_heat_map(processed_buffers_gdf, 'frac_area_tb', 'Tree Canopy Coverage Heat Map')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3caec3c-c3a0-477b-8f7c-89bc959125d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot\n",
    "processed_buffers_gdf['canopy_category'] = pd.qcut(processed_buffers_gdf['frac_area_tb'], 4, labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "sns.boxplot(x='canopy_category', y='NO2_Data', data=processed_buffers_gdf)\n",
    "plt.title('Box Plot of NO2 Concentration by Tree Canopy Coverage')\n",
    "plt.xlabel('Tree Canopy Coverage Category')\n",
    "plt.ylabel('NO2 Concentration')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90eebf-81c2-4186-9b5e-170eba692ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# Step 10: Clip the City-Wide Results to Each District and Save\n",
    "print(\"Step 10: Clip the city-wide results to each district boundary and save them\")\n",
    "districts = [\"Centrum\", \"Nieuw-West\", \"West\", \"Zuid\", \"Noord\", \"Oost\", \"Zuidoost\"]\n",
    "\n",
    "for district_name in districts:\n",
    "    print(f\"Processing {district_name}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Load the district boundary\n",
    "    district_shapefile = os.path.join(district_shp_folder, f\"{district_name}.shp\")\n",
    "    district_boundary = gpd.read_file(district_shapefile)\n",
    "    \n",
    "    # Ensure both datasets have the same CRS\n",
    "    if district_boundary.crs != processed_buffers_gdf.crs:\n",
    "        district_boundary = district_boundary.to_crs(processed_buffers_gdf.crs)\n",
    "\n",
    "    # Check and fix invalid geometries in the district boundary\n",
    "    if not district_boundary.is_valid.all():\n",
    "        print(f\"Fixing invalid geometries for {district_name}\")\n",
    "        district_boundary = district_boundary.buffer(0)\n",
    "    \n",
    "    # Simplify the district boundary to improve performance (optional)\n",
    "    district_boundary = district_boundary.simplify(0.001)  # Adjust tolerance value as needed\n",
    "    \n",
    "    # Clip the city-wide results to the district boundary\n",
    "    try:\n",
    "        district_results = gpd.clip(processed_buffers_gdf, district_boundary)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {district_name}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Convert the categorical 'canopy_category' column to string (if it exists)\n",
    "    if 'canopy_category' in district_results.columns:\n",
    "        district_results['canopy_category'] = district_results['canopy_category'].astype(str)\n",
    "    \n",
    "    # Optionally, rename columns with shorter names to avoid truncation\n",
    "    if 'frac_area_tb' in district_results.columns:\n",
    "        district_results = district_results.rename(columns={'frac_area_tb': 'tree_frac', 'NO2_Data': 'NO2_Data'})\n",
    "\n",
    "    # Save the clipped results\n",
    "    district_output_path = os.path.join(output_folder, f\"processed_buffers_{district_name}.shp\")\n",
    "    try:\n",
    "        district_results.to_file(district_output_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results for {district_name}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Results clipped and saved for {district_name} in {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Histogram for Tree Canopy Coverage in the district\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(district_results['tree_frac'], bins=30, alpha=0.7, label=f'Tree Fraction ({district_name})')\n",
    "    plt.xlabel('Fraction of Tree Canopy Coverage')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of Tree Canopy Coverage Fraction - {district_name}')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot as PNG and show in Jupyter Notebook\n",
    "    output_hist_tree_frac = os.path.join(output_folder, f\"{district_name}_tree_canopy_hist.png\")\n",
    "    plt.savefig(output_hist_tree_frac)\n",
    "    plt.show()\n",
    "\n",
    "    # Histogram for NO2 values for each district\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(district_results['NO2_Data'], bins=30, alpha=0.7, label=f'NO2 Values ({district_name})')\n",
    "    plt.xlabel('NO2 Concentration')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of NO2 Concentration - {district_name}')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot as PNG and show in Jupyter Notebook\n",
    "    output_hist_NO2 = os.path.join(output_folder, f\"{district_name}_NO2_hist.png\")\n",
    "    plt.savefig(output_hist_NO2)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Histograms saved for {district_name}: {output_hist_tree_frac} and {output_hist_NO2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac646b3-5b4b-4fc3-8d1b-f91d07ce47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# Step 10: Clip the City-Wide Results to Each District and Save\n",
    "print(\"Step 10: Clip the city-wide results to each district boundary and save them\")\n",
    "districts = [\"Centrum\", \"Nieuw-West\", \"West\", \"Zuid\", \"Noord\", \"Oost\", \"Zuidoost\"]\n",
    "\n",
    "for district_name in districts:\n",
    "    print(f\"Processing {district_name}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Load the district boundary\n",
    "    district_shapefile = os.path.join(district_shp_folder, f\"{district_name}.shp\")\n",
    "    district_boundary = gpd.read_file(district_shapefile)\n",
    "    \n",
    "    # Ensure both datasets have the same CRS\n",
    "    if district_boundary.crs != processed_buffers_gdf.crs:\n",
    "        district_boundary = district_boundary.to_crs(processed_buffers_gdf.crs)\n",
    "\n",
    "    # Check and fix invalid geometries in the district boundary\n",
    "    if not district_boundary.is_valid.all():\n",
    "        print(f\"Fixing invalid geometries for {district_name}\")\n",
    "        district_boundary = district_boundary.buffer(0)\n",
    "    \n",
    "    # Simplify the district boundary to improve performance (optional)\n",
    "    district_boundary = district_boundary.simplify(0.001)  # Adjust tolerance value as needed\n",
    "    \n",
    "    # Clip the city-wide results to the district boundary\n",
    "    try:\n",
    "        district_results = gpd.clip(processed_buffers_gdf, district_boundary)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {district_name}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Convert the categorical 'canopy_category' column to string (if it exists)\n",
    "    if 'canopy_category' in district_results.columns:\n",
    "        district_results['canopy_category'] = district_results['canopy_category'].astype(str)\n",
    "    \n",
    "    # Optionally, rename columns with shorter names to avoid truncation\n",
    "    if 'frac_area_tb' in district_results.columns:\n",
    "        district_results = district_results.rename(columns={'frac_area_tb': 'tree_frac', 'NO2_Mixed': 'NO2_Mixed'})\n",
    "\n",
    "    # Save the clipped results\n",
    "    district_output_path = os.path.join(output_folder, f\"processed_buffers_{district_name}.shp\")\n",
    "    try:\n",
    "        district_results.to_file(district_output_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results for {district_name}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Results clipped and saved for {district_name} in {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Histogram for Tree Canopy Coverage in the district\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(district_results['tree_frac'], bins=30, alpha=0.7, label=f'Tree Fraction ({district_name})')\n",
    "    plt.xlabel('Fraction of Tree Canopy Coverage')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of Tree Canopy Coverage Fraction - {district_name}')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot as PNG and show in Jupyter Notebook\n",
    "    output_hist_tree_frac = os.path.join(output_folder, f\"{district_name}_tree_canopy_hist.png\")\n",
    "    plt.savefig(output_hist_tree_frac)\n",
    "    plt.show()\n",
    "\n",
    "    # Histogram for NO2 values for each district\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(district_results['NO2_Mixed'], bins=30, alpha=0.7, label=f'NO2  Mixed Values ({district_name})')\n",
    "    plt.xlabel('NO2 Mixed Concentration')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of NO2 Mixed Concentration - {district_name}')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot as PNG and show in Jupyter Notebook\n",
    "    output_hist_NO2 = os.path.join(output_folder, f\"{district_name}_NO2_mixed_hist.png\")\n",
    "    plt.savefig(output_hist_NO2)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Histograms saved for {district_name}: {output_hist_tree_frac} and {output_hist_NO2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e2aba-b2e4-4bce-b48f-7d957db914f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95569fd-0f5f-4b37-a4f2-8fd845e594d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Create Scatter Plots for Each District\n",
    "print(\"Step 11: Create scatter plots for each district\")\n",
    "\n",
    "def create_scatter_plot(district_name, processed_buffers_gdf):\n",
    "    if processed_buffers_gdf.empty:\n",
    "        print(f\"No data available for district: {district_name}\")\n",
    "        return\n",
    "    \n",
    "    # Ensure consistent column names\n",
    "    correlation = processed_buffers_gdf['tree_frac'].corr(processed_buffers_gdf['NO2_Data'])\n",
    "    print(f\"Correlation for {district_name}: {correlation}\")\n",
    "\n",
    "    X = processed_buffers_gdf[['tree_frac']].values.reshape(-1, 1)\n",
    "    y = processed_buffers_gdf['NO2_Data'].values\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    trend_line = model.predict(X)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(processed_buffers_gdf['tree_frac'], processed_buffers_gdf['NO2_Data'], alpha=0.5, label='Data Points')\n",
    "\n",
    "    sorted_indices = np.argsort(processed_buffers_gdf['tree_frac'])\n",
    "    sorted_tree_frac = processed_buffers_gdf['tree_frac'].values[sorted_indices]\n",
    "    sorted_trend_line = trend_line[sorted_indices]\n",
    "\n",
    "    plt.plot(sorted_tree_frac, sorted_trend_line, color='red', label='Trend Line')\n",
    "\n",
    "    plt.title(f'Scatter Plot of Tree Fraction vs. NO2 Data in {district_name}')\n",
    "    plt.xlabel('Fraction of Trees')\n",
    "    plt.ylabel('NO2 Data')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the scatter plot as PNG\n",
    "    scatter_plot_path = os.path.join(output_folder, f\"scatter_plot_{district_name}.png\")\n",
    "    plt.savefig(scatter_plot_path)\n",
    "\n",
    "    # Display the scatter plot in the notebook\n",
    "    plt.show()\n",
    "\n",
    "# Generate scatter plots for each district\n",
    "for district_name in districts:\n",
    "    district_output_path = os.path.join(output_folder, f\"processed_buffers_{district_name}.shp\")\n",
    "    district_results = gpd.read_file(district_output_path)\n",
    "\n",
    "    # Ensure CRS consistency\n",
    "    if district_results.crs != processed_buffers_gdf.crs:\n",
    "        district_results = district_results.to_crs(processed_buffers_gdf.crs)\n",
    "\n",
    "    create_scatter_plot(district_name, district_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de385a5-57ed-4888-8d5d-eedf6fc4215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Create Scatter Plots for Each District\n",
    "print(\"Step 11: Create scatter plots for each district\")\n",
    "\n",
    "def create_scatter_plot(district_name, processed_buffers_gdf):\n",
    "    if processed_buffers_gdf.empty:\n",
    "        print(f\"No data available for district: {district_name}\")\n",
    "        return\n",
    "    \n",
    "    # Ensure consistent column names\n",
    "    correlation = processed_buffers_gdf['tree_frac'].corr(processed_buffers_gdf['NO2_Mixed'])\n",
    "    print(f\"Correlation for {district_name}: {correlation}\")\n",
    "\n",
    "    X = processed_buffers_gdf[['tree_frac']].values.reshape(-1, 1)\n",
    "    y = processed_buffers_gdf['NO2_Mixed'].values\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    trend_line = model.predict(X)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(processed_buffers_gdf['tree_frac'], processed_buffers_gdf['NO2_Mixed'], alpha=0.5, label='Data Points')\n",
    "\n",
    "    sorted_indices = np.argsort(processed_buffers_gdf['tree_frac'])\n",
    "    sorted_tree_frac = processed_buffers_gdf['tree_frac'].values[sorted_indices]\n",
    "    sorted_trend_line = trend_line[sorted_indices]\n",
    "\n",
    "    plt.plot(sorted_tree_frac, sorted_trend_line, color='red', label='Trend Line')\n",
    "\n",
    "    plt.title(f'Scatter Plot of Tree Fraction vs. NO2 Data in {district_name}')\n",
    "    plt.xlabel('Fraction of Trees')\n",
    "    plt.ylabel('NO2 Data Mixed')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the scatter plot as PNG\n",
    "    scatter_plot_path = os.path.join(output_folder, f\"scatter_plot_mixed_{district_name}.png\")\n",
    "    plt.savefig(scatter_plot_path)\n",
    "\n",
    "    # Display the scatter plot in the notebook\n",
    "    plt.show()\n",
    "\n",
    "# Generate scatter plots for each district\n",
    "for district_name in districts:\n",
    "    district_output_path = os.path.join(output_folder, f\"processed_buffers_{district_name}.shp\")\n",
    "    district_results = gpd.read_file(district_output_path)\n",
    "\n",
    "    # Ensure CRS consistency\n",
    "    if district_results.crs != processed_buffers_gdf.crs:\n",
    "        district_results = district_results.to_crs(processed_buffers_gdf.crs)\n",
    "\n",
    "    create_scatter_plot(district_name, district_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3cf7e-cf02-4d13-a34e-00ed682c32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Visualize Clipped Results for Each District to Verify Clipping\n",
    "print(\"Step 13: Visualize Clipped Results for Each District\")\n",
    "\n",
    "def visualize_clipping(district_name, district_boundary, district_results):\n",
    "    # Plot the district boundary and the clipped NO2 data for visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    # Plot the district boundary\n",
    "    district_boundary.boundary.plot(ax=ax, color='blue', linewidth=2, label=f'{district_name} Boundary')\n",
    "    \n",
    "    # Plot the clipped NO2 results\n",
    "    district_results.plot(ax=ax, column='NO2', cmap='YlOrRd', legend=True, alpha=0.6)\n",
    "    \n",
    "    plt.title(f'Clipping Visualization for {district_name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally save the visualization\n",
    "    fig.savefig(os.path.join(output_folder, f\"clipping_visualization_{district_name}.png\"))\n",
    "    print(f\"Clipping visualization saved for {district_name}\")\n",
    "\n",
    "for district_name in districts:\n",
    "    district_output_path = os.path.join(output_folder, f\"processed_buffers_{district_name}.shp\")\n",
    "    district_results = gpd.read_file(district_output_path)\n",
    "\n",
    "    # Load the district boundary again\n",
    "    district_shapefile = os.path.join(district_shp_folder, f\"{district_name}.shp\")\n",
    "    district_boundary = gpd.read_file(district_shapefile)\n",
    "    \n",
    "    # Ensure CRS consistency\n",
    "    if district_boundary.crs != processed_buffers_gdf.crs:\n",
    "        district_boundary = district_boundary.to_crs(processed_buffers_gdf.crs)\n",
    "    \n",
    "    # Visualize the clipping\n",
    "    visualize_clipping(district_name, district_boundary, district_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185dcd70-e3a8-4490-9f8e-faf5a91cea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 13: Create Box Plots for Each District\n",
    "print(\"Step 13: Create Box Plots for Each District\")\n",
    "\n",
    "# Box Plot with Categorized Tree Fractions\n",
    "def create_box_plot(district_name, processed_buffers_gdf):\n",
    "    # Categorize the tree_frac into 4 quartiles\n",
    "    processed_buffers_gdf['tree_frac_cat'] = pd.qcut(processed_buffers_gdf['tree_frac'], q=4, labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='tree_frac_cat', y='NO2_Data', data=processed_buffers_gdf)\n",
    "    plt.title(f'Box Plot of Tree Fraction vs. NO2 Data in {district_name}')\n",
    "    plt.xlabel('Tree Canopy Coverage Category')\n",
    "    plt.ylabel('NO2 Data')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the plot as PNG\n",
    "    output_box_plot_path = os.path.join(output_folder, f\"{district_name}_box_plot_NO2.png\")\n",
    "    plt.savefig(output_box_plot_path)\n",
    "    print(f\"Box Plot saved for {district_name}: {output_box_plot_path}\")\n",
    "\n",
    "    # Show the plot in Jupyter Notebook\n",
    "    plt.show()\n",
    "\n",
    "# Generate box plot for each district\n",
    "for district_name in districts:\n",
    "    district_output_path = os.path.join(output_folder, f\"processed_buffers_{district_name}.shp\")\n",
    "    district_results = gpd.read_file(district_output_path)\n",
    "    \n",
    "    # Ensure CRS consistency\n",
    "    if district_results.crs != processed_buffers_gdf.crs:\n",
    "        district_results = district_results.to_crs(processed_buffers_gdf.crs)\n",
    "\n",
    "    create_box_plot(district_name, district_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca84b90-3e78-4ed7-8e58-4f08c5ab8692",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 13: Create Box Plots for Each District\n",
    "print(\"Step 13: Create Box Plots for Each District\")\n",
    "\n",
    "# Box Plot with Categorized Tree Fractions\n",
    "def create_box_plot(district_name, processed_buffers_gdf):\n",
    "    # Categorize the tree_frac into 4 quartiles\n",
    "    processed_buffers_gdf['tree_frac_cat'] = pd.qcut(processed_buffers_gdf['tree_frac'], q=4, labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='tree_frac_cat', y='NO2_Mixed', data=processed_buffers_gdf)\n",
    "    plt.title(f'Box Plot of Tree Fraction vs. NO2 Data in {district_name}')\n",
    "    plt.xlabel('Tree Canopy Coverage Category')\n",
    "    plt.ylabel('NO2 Data Mixed')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the plot as PNG\n",
    "    output_box_plot_path = os.path.join(output_folder, f\"{district_name}_box_plot_NO2_mixed.png\")\n",
    "    plt.savefig(output_box_plot_path)\n",
    "    print(f\"Box Plot saved for {district_name}: {output_box_plot_path}\")\n",
    "\n",
    "    # Show the plot in Jupyter Notebook\n",
    "    plt.show()\n",
    "\n",
    "# Generate box plot for each district\n",
    "for district_name in districts:\n",
    "    district_output_path = os.path.join(output_folder, f\"processed_buffers_{district_name}.shp\")\n",
    "    district_results = gpd.read_file(district_output_path)\n",
    "    \n",
    "    # Ensure CRS consistency\n",
    "    if district_results.crs != processed_buffers_gdf.crs:\n",
    "        district_results = district_results.to_crs(processed_buffers_gdf.crs)\n",
    "\n",
    "    create_box_plot(district_name, district_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a58631-2c71-465a-b508-3e233ff65bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Create Violin Plots for Each District\n",
    "print(\"Step 14: Create Violin Plots for Each District\")\n",
    "\n",
    "# Violin Plot with Categorized Tree Fractions\n",
    "def create_violin_plot(district_name, processed_buffers_gdf):\n",
    "    # Categorize the tree_frac into 4 quartiles\n",
    "    processed_buffers_gdf['tree_frac_cat'] = pd.qcut(processed_buffers_gdf['tree_frac'], q=4, labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.violinplot(x='tree_frac_cat', y='NO2_Data', data=processed_buffers_gdf, cut=0)\n",
    "    plt.title(f'Violin Plot of Tree Fraction vs. NO2 Data in {district_name}')\n",
    "    plt.xlabel('Tree Canopy Coverage Category')\n",
    "    plt.ylabel('NO2 Data')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the plot as PNG\n",
    "    output_violin_plot_path = os.path.join(output_folder, f\"{district_name}_violin_plot_NO2.png\")\n",
    "    plt.savefig(output_violin_plot_path)\n",
    "    print(f\"Violin Plot saved for {district_name}: {output_violin_plot_path}\")\n",
    "\n",
    "    # Show the plot in Jupyter Notebook\n",
    "    plt.show()\n",
    "\n",
    "# Generate violin plot for each district\n",
    "for district_name in districts:\n",
    "    district_output_path = os.path.join(output_folder, f\"processed_buffers_{district_name}.shp\")\n",
    "    district_results = gpd.read_file(district_output_path)\n",
    "    \n",
    "    # Ensure CRS consistency\n",
    "    if district_results.crs != processed_buffers_gdf.crs:\n",
    "        district_results = district_results.to_crs(processed_buffers_gdf.crs)\n",
    "\n",
    "    create_violin_plot(district_name, district_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d3791-971d-440e-a627-a52cba75bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Create Violin Plots for Each District\n",
    "print(\"Step 14: Create Violin Plots for Each District\")\n",
    "\n",
    "# Violin Plot with Categorized Tree Fractions\n",
    "def create_violin_plot(district_name, processed_buffers_gdf):\n",
    "    # Categorize the tree_frac into 4 quartiles\n",
    "    processed_buffers_gdf['tree_frac_cat'] = pd.qcut(processed_buffers_gdf['tree_frac'], q=4, labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.violinplot(x='tree_frac_cat', y='NO2_Mixed', data=processed_buffers_gdf, cut=0)\n",
    "    plt.title(f'Violin Plot of Tree Fraction vs. NO2 Data Mixed in {district_name}')\n",
    "    plt.xlabel('Tree Canopy Coverage Category')\n",
    "    plt.ylabel('NO2 Data mixed')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the plot as PNG\n",
    "    output_violin_plot_path = os.path.join(output_folder, f\"{district_name}_violin_plot_NO2_mixed.png\")\n",
    "    plt.savefig(output_violin_plot_path)\n",
    "    print(f\"Violin Plot saved for {district_name}: {output_violin_plot_path}\")\n",
    "\n",
    "    # Show the plot in Jupyter Notebook\n",
    "    plt.show()\n",
    "\n",
    "# Generate violin plot for each district\n",
    "for district_name in districts:\n",
    "    district_output_path = os.path.join(output_folder, f\"processed_buffers_{district_name}.shp\")\n",
    "    district_results = gpd.read_file(district_output_path)\n",
    "    \n",
    "    # Ensure CRS consistency\n",
    "    if district_results.crs != processed_buffers_gdf.crs:\n",
    "        district_results = district_results.to_crs(processed_buffers_gdf.crs)\n",
    "\n",
    "    create_violin_plot(district_name, district_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d69d7-e592-426f-a283-b5ba10939238",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate Correlation and Regression Coefficient\n",
    "def calculate_regression(district_name, processed_buffers_gdf):\n",
    "    tree_column = 'tree_frac_cat'  # For categorized tree fraction\n",
    "    no2_column = 'NO2_Data'\n",
    "\n",
    "    correlation = processed_buffers_gdf['tree_frac'].corr(processed_buffers_gdf[no2_column])\n",
    "    print(f\"Correlation for {district_name}: {correlation}\")\n",
    "\n",
    "    # Perform linear regression\n",
    "    X = processed_buffers_gdf[['tree_frac']].values.reshape(-1, 1)  # Use continuous 'tree_frac' for regression\n",
    "    y = processed_buffers_gdf[no2_column].values\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Print regression coefficient and intercept\n",
    "    print(f\"Regression Coefficient for {district_name}: {model.coef_[0]}\")\n",
    "    print(f\"Intercept for {district_name}: {model.intercept_}\")\n",
    "\n",
    "# Calculate correlation and regression for each district\n",
    "for district_name in districts:\n",
    "    district_output_path = os.path.join(output_folder, f\"processed_buffers_{district_name}.shp\")\n",
    "    district_results = gpd.read_file(district_output_path)\n",
    "    \n",
    "    # Ensure CRS consistency\n",
    "    if district_results.crs != processed_buffers_gdf.crs:\n",
    "        district_results = district_results.to_crs(processed_buffers_gdf.crs)\n",
    "\n",
    "    calculate_regression(district_name, district_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf1d20-4a10-4260-9e62-71f53da31300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate Correlation and Regression Coefficient\n",
    "def calculate_regression(district_name, processed_buffers_gdf):\n",
    "    tree_column = 'tree_frac_cat'  # For categorized tree fraction\n",
    "    no2_column = 'NO2_Mixed'\n",
    "\n",
    "    correlation = processed_buffers_gdf['tree_frac'].corr(processed_buffers_gdf[no2_column])\n",
    "    print(f\"Correlation for {district_name}: {correlation}\")\n",
    "\n",
    "    # Perform linear regression\n",
    "    X = processed_buffers_gdf[['tree_frac']].values.reshape(-1, 1)  # Use continuous 'tree_frac' for regression\n",
    "    y = processed_buffers_gdf[no2_column].values\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Print regression coefficient and intercept\n",
    "    print(f\"Regression Coefficient for {district_name}: {model.coef_[0]}\")\n",
    "    print(f\"Intercept for {district_name}: {model.intercept_}\")\n",
    "\n",
    "# Calculate correlation and regression for each district\n",
    "for district_name in districts:\n",
    "    district_output_path = os.path.join(output_folder, f\"processed_buffers_{district_name}.shp\")\n",
    "    district_results = gpd.read_file(district_output_path)\n",
    "    \n",
    "    # Ensure CRS consistency\n",
    "    if district_results.crs != processed_buffers_gdf.crs:\n",
    "        district_results = district_results.to_crs(processed_buffers_gdf.crs)\n",
    "\n",
    "    calculate_regression(district_name, district_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffc4ad8-fdaf-4fef-8031-dac94b89a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mapclassify\n",
    "\n",
    "# Interactive Heat Map with Categorized NO2 Data\n",
    "def create_interactive_heat_map(gdf, column, title, html_output_path):\n",
    "    # Categorize NO2 data using quantiles\n",
    "    gdf['NO2_cat'] = pd.qcut(gdf['NO2'], q=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "    # Create the interactive heatmap\n",
    "    m = gdf.explore(column='NO2_cat', cmap='YlOrRd', legend=True, tooltip=True)\n",
    "    m.save(html_output_path)  # Save as HTML file\n",
    "    return m\n",
    "\n",
    "# Generate heat map for each district\n",
    "for district_name in districts:\n",
    "    district_output_path = os.path.join(output_folder, f\"processed_buffers_{district_name}.shp\")\n",
    "    district_results = gpd.read_file(district_output_path)\n",
    "    \n",
    "    # Ensure CRS consistency\n",
    "    if district_results.crs != processed_buffers_gdf.crs:\n",
    "        district_results = district_results.to_crs(processed_buffers_gdf.crs)\n",
    "\n",
    "    # Generate and display interactive heat map\n",
    "    heatmap_path = os.path.join(output_folder, f'{district_name}_heatmap.html')\n",
    "    create_interactive_heat_map(district_results, 'NO2', f'NO2 Concentration Heat Map - {district_name}', heatmap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13dcdc4-94ba-473e-89b0-9db0d16373b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
